# Sports Injury Risk Prediction - Demo Scripts

This directory contains comprehensive demonstration scripts showcasing all seven dimensions of the Sports Injury Risk Prediction system.

## ğŸ“‹ Overview

The complete demo system covers:

1. **Algorithm Coverage** - Traditional, DL, and Multimodal methods
2. **Architecture Integrity** - Unified interface across all components
3. **Distributed Training** - Multi-GPU support with DeepSpeed/Ray
4. **MLOps Support** - Experiment tracking and profiling
5. **API/Deployment** - Production-ready FastAPI service
6. **Enterprise Features** - Interpretability and risk management
7. **Research Extensions** - Future roadmap and capabilities

## ğŸš€ Quick Start

### Run Complete Demo

```bash
# Run all seven dimensions
./scripts/run_complete_demo.sh
```

This will systematically test and demonstrate all system capabilities.

### Run Individual Demos

```bash
# MLOps: Experiment tracking and profiling
python scripts/demo_mlops.py

# API: Deployment architecture
python scripts/demo_api.py

# Enterprise: Interpretability and validation
python scripts/demo_enterprise.py
```

## ğŸ“ Script Descriptions

### `run_complete_demo.sh`
Master script that runs all seven dimension tests.

**Features:**
- Color-coded output for easy reading
- Progressive execution with status updates
- Checks system capabilities (GPU, dependencies)
- Generates comprehensive summary report

**Output:**
- System status summary table
- Performance benchmarks
- Test coverage report
- Next steps guidance

### `demo_mlops.py`
Demonstrates MLOps infrastructure and practices.

**Components:**
- **MLflow Integration**: Experiment tracking, model registry
- **Weights & Biases**: Real-time visualization, hyperparameter tuning
- **PyTorch Profiler**: Performance analysis, bottleneck detection
- **Model Versioning**: Checkpoint management strategy
- **Monitoring**: Production metrics and alerting

**Usage:**
```python
python scripts/demo_mlops.py
```

### `demo_api.py`
Showcases production deployment architecture.

**Components:**
- **FastAPI Service**: REST API endpoints
- **Request/Response Examples**: Multimodal inputs
- **Docker Deployment**: Containerization strategy
- **Kubernetes**: Orchestration and auto-scaling
- **Model Optimization**: ONNX, TorchScript, quantization

**Usage:**
```python
python scripts/demo_api.py
```

### `demo_enterprise.py`
Demonstrates enterprise-grade features.

**Components:**
- **SHAP Explainability**: Feature importance analysis
- **Grad-CAM**: Visual interpretability for images
- **Attention Visualization**: Cross-modal attention patterns
- **Uncertainty Quantification**: Confidence intervals
- **Model Calibration**: Reliability assessment
- **Fairness Analysis**: Bias detection and mitigation
- **Clinical Validation**: Medical metrics and thresholds
- **Model Governance**: Documentation and compliance

**Usage:**
```python
python scripts/demo_enterprise.py
```

## ğŸ¯ What Each Demo Shows

### 1ï¸âƒ£ Algorithm Coverage Demo

**Traditional Methods:**
- âœ… CHIME Model
- âœ… Logistic Regression
- âœ… Random Forest
- âœ… XGBoost

**Deep Learning Methods:**
- âœ… TransCHIME (Transformer-based)
- âœ… LSTM
- âœ… GRU
- âœ… Transformer

**Multimodal Models:**
- âœ… Vision-Language Model (CLIP + BERT)
- âœ… LoRA Adapters

### 2ï¸âƒ£ Architecture Integrity Demo

Shows unified interface across:
- Data loading (`SportInjuryDataset`)
- Feature engineering (`FeatureEngineer`)
- Model interface (all models share common API)
- Training pipeline (`Trainer`)
- Evaluation metrics (`compute_auc_roc`, `calibration`)

### 3ï¸âƒ£ Distributed Training Demo

**Strategies:**
- Data Parallel (DistributedDataParallel)
- Model Parallel (DeepSpeed ZeRO)
- Pipeline Parallel
- Hybrid Parallel

**Optimizations:**
- Gradient accumulation
- Mixed precision (FP16/BF16)
- Gradient checkpointing
- CPU offloading

### 4ï¸âƒ£ MLOps Support Demo

**Experiment Tracking:**
- MLflow: Parameters, metrics, artifacts
- W&B: Real-time dashboards, sweeps

**Profiling:**
- PyTorch Profiler: CPU/GPU utilization
- Memory profiling
- Bottleneck detection

**Model Management:**
- Version control
- Checkpoint strategies
- Model registry

### 5ï¸âƒ£ API/Deployment Demo

**API Endpoints:**
```
POST /predict          - Single prediction
POST /batch_predict    - Batch processing
GET  /health          - Health check
GET  /model_info      - Model metadata
```

**Deployment:**
- Docker containerization
- Kubernetes orchestration
- Horizontal auto-scaling
- ONNX optimization

### 6ï¸âƒ£ Enterprise Features Demo

**Interpretability:**
- SHAP feature importance
- Grad-CAM visual heatmaps
- Attention weight visualization

**Validation:**
- Uncertainty quantification
- Model calibration (ECE, Brier score)
- Fairness metrics (demographic parity)
- Clinical metrics (sensitivity, specificity)

**Governance:**
- Model cards
- Ethical considerations
- Compliance documentation

### 7ï¸âƒ£ Research Extensions Demo

**Implemented:**
- âœ… Vision-Language Models
- âœ… LoRA adapters
- âœ… TransCHIME architecture
- âœ… Multimodal fusion

**In Progress:**
- ğŸ”„ Video sequence analysis
- ğŸ”„ Adapter fusion strategies
- ğŸ”„ Sparse attention

**Planned:**
- ğŸš€ Continual learning
- ğŸš€ Causal inference
- ğŸš€ Federated learning

## ğŸ“Š Expected Output

### System Status Summary
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      SYSTEM STATUS SUMMARY                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Dimension                 â”‚ Status â”‚ Key Component                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1ï¸âƒ£  Algorithm Coverage    â”‚   âœ…   â”‚ Traditional + DL + Multimodal  â”‚
â”‚ 2ï¸âƒ£  Architecture          â”‚   âœ…   â”‚ Unified Interface              â”‚
â”‚ 3ï¸âƒ£  Distributed Training  â”‚   âš™ï¸   â”‚ Multi-GPU Ready                â”‚
â”‚ 4ï¸âƒ£  MLOps Support         â”‚   âœ…   â”‚ MLflow + W&B                   â”‚
â”‚ 5ï¸âƒ£  API / Deployment      â”‚   ğŸ”„   â”‚ FastAPI + Docker               â”‚
â”‚ 6ï¸âƒ£  Enterprise Features   â”‚   âœ…   â”‚ SHAP + Grad-CAM                â”‚
â”‚ 7ï¸âƒ£  Research Extensions   â”‚   ğŸš€   â”‚ VLM + LoRA + TransCHIME        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Performance Benchmarks
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model             â”‚ Params â”‚ AUC-ROC â”‚ Inferenceâ”‚ Memory  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ XGBoost (Baseline)â”‚   2M   â”‚  0.85   â”‚   3ms    â”‚  0.05GB â”‚
â”‚ TransCHIME        â”‚  10M   â”‚  0.89   â”‚  15ms    â”‚  1.0GB  â”‚
â”‚ VLM (Full)        â”‚ 130M   â”‚  0.93   â”‚  50ms    â”‚  2.0GB  â”‚
â”‚ VLM + LoRA        â”‚  11M   â”‚  0.92   â”‚  40ms    â”‚  1.5GB  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Prerequisites

### Required Dependencies
```bash
# Core ML
pip install torch torchvision transformers

# Multimodal
pip install peft bitsandbytes

# Interpretability
pip install shap captum

# Data processing
pip install pandas numpy scikit-learn

# Optional: MLOps
pip install mlflow wandb
```

### System Requirements
- Python 3.8+
- 8GB+ RAM (16GB+ recommended for multimodal models)
- GPU optional but recommended (CUDA 11.8+ if using GPU)

## ğŸ“ Usage Examples

### Basic Demo Run
```bash
# Quick test - individual components
python scripts/demo_mlops.py
python scripts/demo_api.py
python scripts/demo_enterprise.py

# Full system demo
./scripts/run_complete_demo.sh
```

### With Dependencies Check
```bash
# Install dependencies first
pip install -r requirements.txt

# Run demo
./scripts/run_complete_demo.sh
```

### Customize Output
```bash
# Run specific dimensions only
# Edit run_complete_demo.sh and comment out sections you want to skip

# Example: Skip distributed training demo
# Just comment out the "Dimension 3" section
```

## ğŸ› Troubleshooting

### Script Permission Error
```bash
chmod +x scripts/run_complete_demo.sh
chmod +x scripts/demo_*.py
```

### Missing Dependencies
```bash
pip install torch transformers peft shap captum
```

### GPU Not Detected
- The demo will automatically fall back to CPU mode
- Multi-GPU features will be skipped with appropriate messages

### Import Errors
- Ensure you're running from the project root directory
- Check that `src/` is in your Python path

## ğŸ“š Related Documentation

- **README.md** - Main project overview
- **docs/MULTIMODAL_SYSTEM_ARCHITECTURE.md** - Complete architecture
- **docs/DL_EXPANSION_PLAN.md** - Research roadmap
- **PROJECT_STRUCTURE.md** - Directory structure
- **examples/chime_example.py** - CHIME usage example
- **examples/quick_start.py** - Quick start guide

## ğŸ“ Learning Path

**Beginners:**
1. Run `./scripts/run_complete_demo.sh` to see overview
2. Study `demo_enterprise.py` for interpretability basics
3. Explore `examples/chime_example.py` for hands-on training

**Intermediate:**
1. Deep dive into `demo_mlops.py` for experiment tracking
2. Review `demo_api.py` for deployment patterns
3. Study docs/MULTIMODAL_SYSTEM_ARCHITECTURE.md

**Advanced:**
1. Implement custom distributed training strategies
2. Extend multimodal fusion architectures
3. Contribute to research extensions roadmap

## ğŸ¤ Contributing

If you add new features, please update the corresponding demo script:
- New models â†’ Update Algorithm Coverage section
- New interpretability â†’ Update `demo_enterprise.py`
- New deployment â†’ Update `demo_api.py`
- New MLOps tools â†’ Update `demo_mlops.py`

## ğŸ“§ Support

For issues or questions:
1. Check this README and related docs
2. Review demo script output for hints
3. Inspect script source code for implementation details
4. Check project documentation in `docs/`

---

**Last Updated:** 2025-10-17
**Status:** âœ… All demos functional
**Version:** 1.0.0
